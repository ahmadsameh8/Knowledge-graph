{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0c2f08",
   "metadata": {},
   "source": [
    "# Extracting Data from separate cases to one json case file, while filtereing only relevent metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17dbcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_cases(source_file, target_file):\n",
    "    \"\"\"\n",
    "    Extracts filtered case data from a JSON input file and saves to target file,\n",
    "    including only the newest decision for each case. Appends or updates cases if target exists.\n",
    "    \"\"\"\n",
    "    # --- Load source JSON ---\n",
    "    with open(source_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # --- Load or initialize target JSON ---\n",
    "    if os.path.exists(target_file):\n",
    "        with open(target_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                existing_cases = json.load(f)\n",
    "            except json.JSONDecodeError:\n",
    "                existing_cases = {}\n",
    "    else:\n",
    "        existing_cases = {}\n",
    "\n",
    "    def first_or_empty(value):\n",
    "        \"\"\"Return first element if list, otherwise value or empty string.\"\"\"\n",
    "        if isinstance(value, list):\n",
    "            return value[0] if value else \"\"\n",
    "        return value or \"\"\n",
    "\n",
    "    def parse_json_str(value):\n",
    "        \"\"\"Safely parse a JSON string like '{\"code\":\"x\",\"label\":\"y\"}'.\"\"\"\n",
    "        if isinstance(value, str):\n",
    "            try:\n",
    "                return json.loads(value)\n",
    "            except json.JSONDecodeError:\n",
    "                return {}\n",
    "        return value if isinstance(value, dict) else {}\n",
    "\n",
    "    def parse_date(date_str):\n",
    "        \"\"\"Parse a date string to datetime for sorting (fallback to None).\"\"\"\n",
    "        if not date_str:\n",
    "            return None\n",
    "        try:\n",
    "            return datetime.fromisoformat(date_str.replace(\"Z\", \"+00:00\"))\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    # --- Process each case ---\n",
    "    for case_id, case_data in data.items():\n",
    "        metadata = case_data.get(\"metadata\", {})\n",
    "        decisions = case_data.get(\"decisions\", [])\n",
    "\n",
    "        # --- Find the newest decision ---\n",
    "        newest_decision = None\n",
    "        newest_date = None\n",
    "        for decision in decisions:\n",
    "            dec_meta = decision.get(\"metadata\", {})\n",
    "            adoption_dates = dec_meta.get(\"decisionAdoptionDate\", [])\n",
    "            adoption_date = first_or_empty(adoption_dates)\n",
    "            parsed_date = parse_date(adoption_date)\n",
    "            if parsed_date and (newest_date is None or parsed_date > newest_date):\n",
    "                newest_date = parsed_date\n",
    "                newest_decision = decision\n",
    "\n",
    "        # --- Extract decision details ---\n",
    "        decision_label = \"\"\n",
    "        if newest_decision:\n",
    "            dec_meta = newest_decision.get(\"metadata\", {})\n",
    "            decision_types = dec_meta.get(\"decisionTypes\")\n",
    "            if isinstance(decision_types, list) and decision_types:\n",
    "                dec_item = decision_types[-1]\n",
    "                dec_obj = parse_json_str(dec_item)\n",
    "                decision_label = dec_obj.get(\"label\", \"\")\n",
    "\n",
    "        # --- Handle case sectors ---\n",
    "        sector_code = sector_label = \"\"\n",
    "        case_sectors = metadata.get(\"caseSectors\", [])\n",
    "        if isinstance(case_sectors, list) and case_sectors:\n",
    "            sec_item = parse_json_str(case_sectors[0])\n",
    "            sector_code = sec_item.get(\"code\", \"\")\n",
    "            sector_label = sec_item.get(\"label\", \"\")\n",
    "\n",
    "        # --- Handle caseLegalBasis (always list for labels) ---\n",
    "        legal_basis_list = metadata.get(\"caseLegalBasis\", [])\n",
    "        case_legal_basis_code = \"\"\n",
    "        case_legal_basis_label = []\n",
    "\n",
    "        if isinstance(legal_basis_list, list) and legal_basis_list:\n",
    "            for lb_entry in legal_basis_list:\n",
    "                lb_obj = parse_json_str(lb_entry)\n",
    "                if lb_obj:\n",
    "                    case_legal_basis_code = lb_obj.get(\"code\", case_legal_basis_code)\n",
    "                    label = lb_obj.get(\"label\", \"\")\n",
    "                    if isinstance(label, str) and label:\n",
    "                        parts = [p.strip() for p in label.split(\"+\")]\n",
    "                        case_legal_basis_label.extend(parts)\n",
    "\n",
    "        # --- Handle caseCompanies (always list, split by \"/\") ---\n",
    "        companies_raw = metadata.get(\"caseCompanies\", [])\n",
    "        companies = []\n",
    "\n",
    "        if isinstance(companies_raw, list) and companies_raw:\n",
    "            for c in companies_raw:\n",
    "                if isinstance(c, str):\n",
    "                    # Split by \"/\" if multiple companies listed together\n",
    "                    parts = [p.strip() for p in c.split(\"/\") if p.strip()]\n",
    "                    companies.extend(parts)\n",
    "        elif isinstance(companies_raw, str):\n",
    "            companies = [p.strip() for p in companies_raw.split(\"/\") if p.strip()]\n",
    "\n",
    "        # --- Flatten and build output ---\n",
    "        filtered_case = {\n",
    "            \"caseInstrument\": first_or_empty(metadata.get(\"caseInstrument\")),\n",
    "            \"caseNumber\": first_or_empty(metadata.get(\"caseNumberPart\")),\n",
    "            \"caseTitle\": first_or_empty(metadata.get(\"caseTitle\")),\n",
    "            \"caseSectorsCode\": sector_code,\n",
    "            \"caseSectorLabel\": sector_label,\n",
    "            \"caseCompanies\": companies,  \n",
    "            \"caseLegalBasisCode\": case_legal_basis_code,\n",
    "            \"caseLegalBasisLabel\": case_legal_basis_label,  \n",
    "            \"caseLastDecisionDate\": first_or_empty(metadata.get(\"caseLastDecisionDate\")),\n",
    "            \"caseInitiationDate\": first_or_empty(metadata.get(\"caseInitiationDate\")),\n",
    "            \"decisionLabel\": decision_label\n",
    "        }\n",
    "\n",
    "        existing_cases[case_id] = filtered_case\n",
    "\n",
    "    # --- Save result ---\n",
    "    with open(target_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(existing_cases, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"✅ Extracted {len(existing_cases)} cases and saved to '{target_file}' (newest decisions only).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99343c8d",
   "metadata": {},
   "source": [
    "# Fills all Merger cases with a legal basis = Art. 105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f94b8c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_merger_legal_basis(json_file, fill_value=\"Art. 105\"):\n",
    "    \"\"\"\n",
    "    Update all cases with caseInstrument == 'Merger' and null/empty caseLegalBasisLabel\n",
    "    to a specified fill_value.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    count = 0\n",
    "    for case in data.values():\n",
    "        instrument = case.get(\"caseInstrument\", \"\")\n",
    "        basis_labels = case.get(\"caseLegalBasisLabel\")\n",
    "        is_basis_null = (\n",
    "            basis_labels is None\n",
    "            or (isinstance(basis_labels, list) and not basis_labels)\n",
    "            or (isinstance(basis_labels, str) and (basis_labels.strip() == \"\" or basis_labels.strip().lower() == \"null\"))\n",
    "        )\n",
    "        if instrument == \"Merger\" and is_basis_null:\n",
    "            case[\"caseLegalBasisLabel\"] = [fill_value]\n",
    "            count += 1\n",
    "\n",
    "    with open(json_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"✅ Filled {count} 'Merger' cases with missing caseLegalBasisLabel!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be87b4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted 9814 cases and saved to 'cases.json' (newest decisions only).\n",
      "✅ Filled 9814 'Merger' cases with missing caseLegalBasisLabel!\n",
      "✅ Extracted 10548 cases and saved to 'cases.json' (newest decisions only).\n"
     ]
    }
   ],
   "source": [
    "extract_cases(\"case-data-M.json\", \"cases.json\")\n",
    "\n",
    "fill_merger_legal_basis(\"cases.json\")\n",
    "\n",
    "extract_cases(\"case-data-AT.json\", \"cases.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "246b5222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique legal basis: 12\n",
      "- Art 23(1)e Regulation 2003/1\n",
      "- Art 258 TFEU (Ex 226 EC)\n",
      "- Art 65 ECSC Treaty\n",
      "- Art. 101\n",
      "- Art. 102\n",
      "- Art. 105\n",
      "- Art. 106\n",
      "- Art. 37\n",
      "- Art. 4 TFEU\n",
      "- Art. 53\n",
      "- Art. 54\n",
      "- Art. 7 Reg.2003/1228\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def list_unique_legal_basis(json_file):\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    legal_bases = set()\n",
    "    for case in data.values():\n",
    "        labels = case.get(\"caseLegalBasisLabel\", [])\n",
    "        if isinstance(labels, str):  # Handle string accidentally present\n",
    "            labels = [labels]\n",
    "        for label in labels:\n",
    "            if isinstance(label, str) and label.strip():\n",
    "                legal_bases.add(label.strip())\n",
    "\n",
    "    print(f\"Total unique legal basis: {len(legal_bases)}\")\n",
    "    for b in sorted(legal_bases):\n",
    "        print(\"-\", b)\n",
    "\n",
    "# Usage example:\n",
    "list_unique_legal_basis(\"cases.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea63fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove\n",
    "# Art 23(1)e Regulation 2003/1\n",
    "# - Art 258 TFEU (Ex 226 EC)\n",
    "# - Art 65 ECSC Treaty\n",
    "# - Art. 37\n",
    "# - Art. 4 TFEU\n",
    "# - Art. 53\n",
    "# - Art. 54\n",
    "# - Art. 37\n",
    "# - Art. 7 Reg.2003/1228\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60082f6",
   "metadata": {},
   "source": [
    "# Normalizes legal basis variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dbda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Mapping of patterns to normalized values\n",
    "mapping = {\n",
    "    \"Art. 101 TFEU\": \"Art. 101\",\n",
    "    \"Art. 101\": \"Art. 101\",\n",
    "    \"Art. 102 TFEU\": \"Art. 102\",\n",
    "    \"Art. 102\": \"Art. 102\",\n",
    "    \"Art. 105 TFEU\": \"Art. 105\",\n",
    "    \"Art. 105 TFEU (Ex 85 EC)\": \"Art. 105\",\n",
    "    \"Art 105 TFEU (Ex 85 EC)\" : \"Art. 105\",\n",
    "    \"Art. 106\": \"Art. 106\",\n",
    "    \"Art. 106 TFEU\": \"Art. 106\",\n",
    "    \"Art. 106 TFEU (Ex 86 EC)\": \"Art. 106\",\n",
    "    \"Art 106 TFEU (Ex 86 EC)\" : \"Art. 106\",\n",
    "    \"Art. 53 EEA\": \"Art. 53\",\n",
    "    \"Art. 53\": \"Art. 53\",\n",
    "    \"Art. 54 EEA\": \"Art. 54\",\n",
    "    \"Art. 54\": \"Art. 54\"\n",
    "}\n",
    "\n",
    "def normalize_legal_basis(json_file, mapping, save_as=None):\n",
    "    \"\"\"\n",
    "    For all cases in json_file, normalize `caseLegalBasisLabel` values according to mapping dict.\n",
    "    Saves to the same file unless save_as is specified.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    for case_id, case_data in data.items():\n",
    "        if \"caseLegalBasisLabel\" in case_data:\n",
    "            labels = case_data[\"caseLegalBasisLabel\"]\n",
    "            # Defensive: sometimes might be string/null, not list\n",
    "            if isinstance(labels, str):\n",
    "                labels = [labels]\n",
    "            case_data[\"caseLegalBasisLabel\"] = [\n",
    "                mapping.get(label.strip(), label.strip())\n",
    "                for label in labels if isinstance(label, str) and label.strip()\n",
    "            ]\n",
    "    out_file = save_as or json_file\n",
    "    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"✅ Legal basis normalization complete! Saved as {out_file}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab5725d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Legal basis normalization complete! Saved as cases.json\n"
     ]
    }
   ],
   "source": [
    "normalize_legal_basis(\"cases.json\", mapping, save_as=\"cases.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8fc3a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_unique_legal_basis(\"cases.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94f91ce",
   "metadata": {},
   "source": [
    "# Cleaning and parsing caseSectorLabel based on the NACE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25ed0c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done! Saved as cases.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# NACE section names\n",
    "NACE_SECTIONS = {\n",
    "    \"A\": \"AGRICULTURE, FORESTRY AND FISHING\",\n",
    "    \"B\": \"MINING AND QUARRYING\",\n",
    "    \"C\": \"MANUFACTURING\",\n",
    "    \"D\": \"ELECTRICITY, GAS, STEAM AND AIR CONDITIONING SUPPLY\",\n",
    "    \"E\": \"WATER SUPPLY; SEWERAGE, WASTE MANAGEMENT AND REMEDIATION ACTIVITIES\",\n",
    "    \"F\": \"CONSTRUCTION\",\n",
    "    \"G\": \"WHOLESALE AND RETAIL TRADE; REPAIR OF MOTOR VEHICLES AND MOTORCYCLES\",\n",
    "    \"H\": \"TRANSPORTATION AND STORAGE\",\n",
    "    \"I\": \"ACCOMMODATION AND FOOD SERVICE ACTIVITIES\",\n",
    "    \"J\": \"INFORMATION AND COMMUNICATION\",\n",
    "    \"K\": \"FINANCIAL AND INSURANCE ACTIVITIES\",\n",
    "    \"L\": \"REAL ESTATE ACTIVITIES\",\n",
    "    \"M\": \"PROFESSIONAL, SCIENTIFIC AND TECHNICAL ACTIVITIES\",\n",
    "    \"N\": \"ADMINISTRATIVE AND SUPPORT SERVICE ACTIVITIES\",\n",
    "    \"O\": \"PUBLIC ADMINISTRATION AND DEFENCE; COMPULSORY SOCIAL SECURITY\",\n",
    "    \"P\": \"EDUCATION\",\n",
    "    \"Q\": \"HUMAN HEALTH AND SOCIAL WORK ACTIVITIES\",\n",
    "    \"R\": \"ARTS, ENTERTAINMENT AND RECREATION\",\n",
    "    \"S\": \"OTHER SERVICE ACTIVITIES\",\n",
    "    \"T\": \"ACTIVITIES OF HOUSEHOLDS AS EMPLOYERS; UNDIFFERENTIATED GOODS- AND SERVICES-PRODUCING ACTIVITIES OF HOUSEHOLDS FOR OWN USE\",\n",
    "    \"U\": \"ACTIVITIES OF EXTRATERRITORIAL ORGANISATIONS AND BODIES\"\n",
    "}\n",
    "\n",
    "\n",
    "def parse_sector_metadata(raw_sector: str):\n",
    "    \"\"\"Parse a raw sector label into structured sector metadata.\"\"\"\n",
    "    if not raw_sector or not isinstance(raw_sector, str):\n",
    "        return None\n",
    "\n",
    "    raw_sector = raw_sector.strip()\n",
    "\n",
    "    # Split description\n",
    "    parts = raw_sector.split(\" - \")\n",
    "    code_part = parts[0].strip()\n",
    "    description = parts[1].strip() if len(parts) > 1 else None\n",
    "\n",
    "    # Extract the section letter\n",
    "    section_code = code_part[0] if code_part else None\n",
    "    section_name = NACE_SECTIONS.get(section_code, None)\n",
    "\n",
    "    # Extract numeric parts (e.g., 21, 20)\n",
    "    numeric_parts = re.findall(r\"\\d+\", code_part)\n",
    "    division = numeric_parts[0] if len(numeric_parts) >= 1 else None\n",
    "    group = numeric_parts[1][0] if len(numeric_parts) >= 2 else None\n",
    "    class_code = numeric_parts[1][1:] if len(numeric_parts) >= 2 and len(numeric_parts[1]) > 1 else None\n",
    "\n",
    "    return {\n",
    "        \"sectionCode\": section_code,\n",
    "        \"sectionName\": section_name,\n",
    "        \"division\": division,\n",
    "        \"group\": group,\n",
    "        \"classCode\": class_code,\n",
    "        \"classDescription\": description\n",
    "    }\n",
    "\n",
    "\n",
    "# === Load your JSON file ===\n",
    "with open(\"cases.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === Transform ===\n",
    "for case_id, case_data in data.items():\n",
    "    raw_sector = case_data.get(\"caseSectorLabel\")\n",
    "    sector_meta = parse_sector_metadata(raw_sector)\n",
    "    case_data[\"sector_metadata\"] = sector_meta\n",
    "\n",
    "# === Save ===\n",
    "with open(\"cases.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ Done! Saved as cases.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dc9aa1",
   "metadata": {},
   "source": [
    "# Converting the Json to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b69c654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON successfully converted to cases.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"cases.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "records = []\n",
    "for case_id, case_data in data.items():\n",
    "    # Get the nested metadata safely\n",
    "    sector_meta = case_data.get(\"sector_metadata\") or {}\n",
    "\n",
    "    record = {\n",
    "        \"caseId\": case_id,\n",
    "        \"caseInstrument\": case_data.get(\"caseInstrument\") or None,\n",
    "        \"caseNumber\": case_data.get(\"caseNumber\") or None,\n",
    "        \"caseTitle\": case_data.get(\"caseTitle\") or None,\n",
    "        \"caseSectorLabel\": case_data.get(\"caseSectorLabel\") or None,\n",
    "        \"caseLastDecisionDate\": case_data.get(\"caseLastDecisionDate\") or None,\n",
    "        \"caseInitiationDate\": case_data.get(\"caseInitiationDate\") or None,\n",
    "        \"decisionLabel\": case_data.get(\"decisionLabel\") or None,\n",
    "        \"sectionCode\": sector_meta.get(\"sectionCode\") or None,\n",
    "        \"sectionName\": sector_meta.get(\"sectionName\") or None,\n",
    "        \"division\": sector_meta.get(\"division\") or None,\n",
    "        \"group\": sector_meta.get(\"group\") or None,\n",
    "        \"classCode\": sector_meta.get(\"classCode\") or None,\n",
    "        \"classDescription\": sector_meta.get(\"classDescription\") or None,\n",
    "        \"caseCompanies\": \"; \".join(case_data.get(\"caseCompanies\", [])) or None,\n",
    "        \"caseLegalBasisLabel\": \"; \".join(case_data.get(\"caseLegalBasisLabel\", [])) or None,\n",
    "    }\n",
    "\n",
    "    records.append(record)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Replace empty strings with None\n",
    "df.replace({\"\": np.nan}, inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"cases.csv\", index=False, encoding=\"utf-8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b1b528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Clean CSV saved as cases_clean.csv with nulls for missing or blank values.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"cases.csv\")\n",
    "\n",
    "# Replace empty or invalid values with null\n",
    "df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "df = df.replace('NaN', np.nan)\n",
    "df = df.replace('nan', np.nan)\n",
    "\n",
    "# Save clean CSV\n",
    "df.to_csv(\"cases.csv\", index=False, na_rep=\"null\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "658b1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "COMPANIES_TO_REMOVE = {\"JV\", \"KKR\", \"CVC\"}\n",
    "\n",
    "def clean_companies(companies_str: str) -> str:\n",
    "    if pd.isna(companies_str):\n",
    "        return companies_str\n",
    "\n",
    "    cleaned = []\n",
    "    for comp in companies_str.split(\";\"):\n",
    "        comp = comp.strip()\n",
    "        if comp and comp.upper() not in COMPANIES_TO_REMOVE:\n",
    "            cleaned.append(comp)\n",
    "\n",
    "    return \";\".join(cleaned)\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"cases.csv\")\n",
    "\n",
    "# Clean company names\n",
    "df[\"caseCompanies\"] = df[\"caseCompanies\"].apply(clean_companies)\n",
    "\n",
    "df.to_csv(\"cases.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
